#!/usr/bin/perl

# conditional_entropy.pl v0.1.0
# Author: MH Seabolt
# Last updated: 8-21-2021

# SYNOPSIS
# Calculates the conditional entropy H(Y|X) between two random variables X and Y, given as two input matrices P (representing X) and Q (representing Y).
# Currently only handles TWO matrices, a more elaborate program will have to be written in the future to generalize conditional entropy to multiple variables.
# Expects that both matrices are formatted in the same way.

# Note: This program internally calculates the joint probability distribution of the two random variables.  Do not supply a joint probability distribution as input to this program.

##################################################################################
# The MIT License
#
# Copyright (c) 2021 Matthew H. Seabolt
#
# Permission is hereby granted, free of charge, 
# to any person obtaining a copy of this software and 
# associated documentation files (the "Software"), to 
# deal in the Software without restriction, including 
# without limitation the rights to use, copy, modify, 
# merge, publish, distribute, sublicense, and/or sell 
# copies of the Software, and to permit persons to whom 
# the Software is furnished to do so, 
# subject to the following conditions:
#
# The above copyright notice and this permission notice 
# shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. 
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR 
# ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, 
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE 
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
##################################################################################

use strict;
use warnings;
use Getopt::Long qw(GetOptions);

# GetOpts Variable declarations
my $input1 = "--";
my $input2;
my $output = "--";
my $cns = 1;
my $rns = 1;
my $sep;
my $outfmt;

sub usage {
	my $usage = "conditional_entropy.pl v0.1.0\n
	PURPOSE: Calculates the conditional entropy H(Y|X) between two random variables X and Y, given as two input matrices P (representing X) and Q (representing Y).
			Currently only handles TWO matrices, a more elaborate program will have to be written in the future to generalize conditional entropy to multiple variables.
			Expects that both matrices are formatted in the same way.
			
			Note: This program internally calculates the joint probability distribution of the two random variables.  Do not supply
			a joint probability distribution as input to this program.
	\n
	USAGE:	conditional_entropy.pl v0.1.0 -P data1.tab -Q data2.tab -o conditional_entropy.tab
	-P		first input matrix P
	-Q 		second input matrix Q, formatted the same as the first matrix.
	-o 		output file name ( do not include extensions! )
	-c 		INT flag; matrix contains column headers? ( Default: ON )
	-r 		INT flag; matrix contains row names? ( Default: ON )
	-s 		STR; input data separator. ( Default: tab )
\n";
	print $usage;
}

GetOptions(	'1|P=s' => \$input1, 
			'2|Q=s' => \$input2,
			'out|o=s' => \$output,
			'colnames|c=i' => \$cns,
			'rownames|r=i' => \$rns,
			'sep|s=s' => \$sep,
) or die usage();

# Parameter setups
$cns = ( $cns && $cns == 0 )? 0 : 1;
$rns = ( $rns && $rns == 0 )? 0 : 1;
$sep = ( $sep && $sep ne "\t" )? $sep : "\t";

##################################################################################
# Read the first input data file
my $fh = *STDIN;
my $succin = open(MATRIX1, "<", "$input1") if ( $input1 ne "--" && -e $input1 );
$fh = *MATRIX1 if ( $succin ); 

# Initialize a vector for rownames
my @rownames;

# Operate on the matrix line-by-line (here we are skipping column headers and rownames, if they are marked as being present
my @P;
my @p_marginal;
my $p_sum = 0;
while ( <$fh> )		{
	chomp $_;
	if ( $cns == 1 && $. == 1 )		{
		next;
	}
	my @row = split("$sep", $_);
	if ( $rns == 1 )	{
		my $rowname = shift @row;
		push @rownames, $rowname;
	}
	my $row_sum = sum(@row);
	push @p_marginal, $row_sum;
	$p_sum += $row_sum;
	push @P, \@row;
}
close $fh if ( $succin );

##################################################################################
# Read the second matrix, which must come from a file and have the same formatting as the first matrix
open(MATRIX2, "<", "$input2" ) or die "conditional_entropy::FATAL ERROR with 2nd input file $input2 --> $!\n";
	my @data2 = <MATRIX2>;
close MATRIX2;

# Operate on the matrix line-by-line
my @q_marginal;
my $q_sum = 0;
for ( my $i=0; $i < scalar @data2; $i++ )	{
	chomp $data2[$i];
	if ( $cns == 1 && $i == 0 )		{
		next;
	}
	my @row = split("$sep", $data2[$i]);
	if ( $rns == 1 )		{
		my $rowname = shift @row ;
	}
	my $row_sum = sum(@row);
	push @q_marginal, $row_sum;
	$q_sum += $row_sum;
}

# Sanity check
die "conditional_entropy::FATAL ERROR --> Distributions do not have the same dimensions!\n" if ( scalar @p_marginal != scalar @q_marginal );

##################################################################################
# Calculate the joint distribution from the data

# Open the output filehandle
my $succout = open( OUT, ">", "$output" ) if $output ne "--";
my $fhout;
if ( $succout )		{	$fhout = *OUT;		}
else				{	$fhout = *STDOUT;	}
print $fhout "Nats\n" if ( $cns == 1 );

# Calculate the joint PROBABILITY distribution P(x,y)
my $conditional_entropy = 0;
my $joint_total = $p_sum * $q_sum;
for ( my $i=0; $i < scalar @p_marginal; $i++ )		{
	my @joint_row;
	for ( my $j=0; $j < scalar @q_marginal; $j++ )	{
		push @joint_row, ($p_marginal[$i] * $q_marginal[$j]) / ($p_sum * $q_sum);
	}
	$conditional_entropy += conditional_entropy(@joint_row);
}
if ( $rns == 1 )	{	print $fhout join("$sep", "H(Y|X)", $conditional_entropy),"\n";		}
else 				{ 	print $fhout "$conditional_entropy\n";								}
close $fhout if ( $succout );
exit;


#################################### SUBROUTINES ##################################

# Calculates conditional entropy H(Y|X)
sub conditional_entropy		{
	my ( @sample ) = @_;
	
	# Error handling: return 0 if $N is zero
	my $N = sum( @sample );
	return ( 0 ) if ( $N == 0 );		
	
	# Calculate *p* for each species *i*
	my @pis;
	for ( my $i=0; $i < scalar @sample; $i++ )	{
		$pis[$i] = ( $sample[$i] == 0 )? 0 : ($sample[$i]) * log( $sample[$i] / ($p_marginal[$i]/$p_sum) );
	}

	# Sum @pis and multiply by -1
	my $H = -( sum(@pis) );
	return $H;
}

sub sum		{
	my ( @list ) = @_;
	my $sum = 0;
	$sum += $_ foreach ( @list );
	return $sum;
}


